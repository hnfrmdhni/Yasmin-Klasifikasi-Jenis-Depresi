{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Library yang dibutuhin dulu\n",
        "# !!!! PASTIKAN PAKAI VIRTUAL ENVIRONMENT (.venv) AGAR TIDAK BENTROK !!!!\n",
        "# bisa jalankan cell ini atau copas syntaxnya, jalankan di terminal\n",
        "\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:06.486486Z",
          "iopub.status.busy": "2024-08-29T16:50:06.486083Z",
          "iopub.status.idle": "2024-08-29T16:50:09.681404Z",
          "shell.execute_reply": "2024-08-29T16:50:09.68025Z",
          "shell.execute_reply.started": "2024-08-29T16:50:06.486443Z"
        },
        "id": "7_QRzVSafiJO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import re\n",
        "import random\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from scipy.sparse import hstack  # To combine sparse matrices\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:09.684077Z",
          "iopub.status.busy": "2024-08-29T16:50:09.683208Z",
          "iopub.status.idle": "2024-08-29T16:50:10.677355Z",
          "shell.execute_reply": "2024-08-29T16:50:10.67625Z",
          "shell.execute_reply.started": "2024-08-29T16:50:09.684036Z"
        },
        "id": "fgKT8c8dfiJP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Reading dataset\n",
        "df = pd.read_csv('data/dataset1.csv', index_col=0)  # Dataset klasifikasi depresi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.679163Z",
          "iopub.status.busy": "2024-08-29T16:50:10.678724Z",
          "iopub.status.idle": "2024-08-29T16:50:10.696183Z",
          "shell.execute_reply": "2024-08-29T16:50:10.695048Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.679116Z"
        },
        "id": "JaT0uto3fiJQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.699589Z",
          "iopub.status.busy": "2024-08-29T16:50:10.69914Z",
          "iopub.status.idle": "2024-08-29T16:50:10.81131Z",
          "shell.execute_reply": "2024-08-29T16:50:10.810219Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.699538Z"
        },
        "id": "PeIyGo01fiJR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.813347Z",
          "iopub.status.busy": "2024-08-29T16:50:10.812866Z",
          "iopub.status.idle": "2024-08-29T16:50:10.843087Z",
          "shell.execute_reply": "2024-08-29T16:50:10.841645Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.813289Z"
        },
        "id": "AttBxGQzfiJR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db5MTzdifiJS"
      },
      "source": [
        "### Removing missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.845536Z",
          "iopub.status.busy": "2024-08-29T16:50:10.84497Z",
          "iopub.status.idle": "2024-08-29T16:50:10.869086Z",
          "shell.execute_reply": "2024-08-29T16:50:10.867891Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.845468Z"
        },
        "id": "cgfVBp7bfiJT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.871305Z",
          "iopub.status.busy": "2024-08-29T16:50:10.870805Z",
          "iopub.status.idle": "2024-08-29T16:50:10.91036Z",
          "shell.execute_reply": "2024-08-29T16:50:10.909341Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.87122Z"
        },
        "id": "32m439mSfiJT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace = True)\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAhqRx9jfiJU"
      },
      "source": [
        "### Looking at target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.912294Z",
          "iopub.status.busy": "2024-08-29T16:50:10.911921Z",
          "iopub.status.idle": "2024-08-29T16:50:10.928191Z",
          "shell.execute_reply": "2024-08-29T16:50:10.927002Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.912254Z"
        },
        "id": "4ENj2B6ofiJU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.status.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:10.930553Z",
          "iopub.status.busy": "2024-08-29T16:50:10.930119Z",
          "iopub.status.idle": "2024-08-29T16:50:11.392647Z",
          "shell.execute_reply": "2024-08-29T16:50:11.391475Z",
          "shell.execute_reply.started": "2024-08-29T16:50:10.930497Z"
        },
        "id": "KAQ6k9PjfiJU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the occurrences of each category\n",
        "status_counts = df['status'].value_counts()\n",
        "\n",
        "# Define colors for each category (7 colors)\n",
        "colors = ['#419D78', '#E0A458', '#2D3047', '#FFDBB5', '#C04ABC', '#B3CDE0', '#D0D0D0']\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%',\n",
        "        startangle=140, colors=colors, shadow=True)\n",
        "\n",
        "plt.title('Distribution of Mental Health Conditions')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
        "\n",
        "# Display the chart\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:11.397671Z",
          "iopub.status.busy": "2024-08-29T16:50:11.396852Z",
          "iopub.status.idle": "2024-08-29T16:50:11.422492Z",
          "shell.execute_reply": "2024-08-29T16:50:11.421434Z",
          "shell.execute_reply.started": "2024-08-29T16:50:11.397624Z"
        },
        "id": "c3fmyJnyfiJW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Group by status and get a random statement from each group\n",
        "random_statements = df.groupby('status')['statement'].apply(lambda x: x.sample(n=1).iloc[0])\n",
        "\n",
        "# Print the results\n",
        "for status, statement in random_statements.items():\n",
        "    print(f\"Status: {status}\")\n",
        "    print(f\"Statement: {statement}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:11.423988Z",
          "iopub.status.busy": "2024-08-29T16:50:11.423659Z",
          "iopub.status.idle": "2024-08-29T16:50:37.587301Z",
          "shell.execute_reply": "2024-08-29T16:50:37.586196Z",
          "shell.execute_reply.started": "2024-08-29T16:50:11.423949Z"
        },
        "id": "23v-gnuHfiJX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate the number of characters and sentences\n",
        "df['num_of_characters'] = df['statement'].str.len()\n",
        "df['num_of_sentences'] = df['statement'].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
        "\n",
        "# Generate descriptive statistics\n",
        "description = df[['num_of_characters', 'num_of_sentences']].describe()\n",
        "\n",
        "# Display the descriptive statistics\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:37.588987Z",
          "iopub.status.busy": "2024-08-29T16:50:37.588652Z",
          "iopub.status.idle": "2024-08-29T16:50:37.604832Z",
          "shell.execute_reply": "2024-08-29T16:50:37.603676Z",
          "shell.execute_reply.started": "2024-08-29T16:50:37.588952Z"
        },
        "id": "4pym5NZKfiJX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[df['num_of_characters'] > 10000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR21OKiHfiJX"
      },
      "source": [
        "# TEXT PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:37.606539Z",
          "iopub.status.busy": "2024-08-29T16:50:37.606186Z",
          "iopub.status.idle": "2024-08-29T16:50:37.730778Z",
          "shell.execute_reply": "2024-08-29T16:50:37.729856Z",
          "shell.execute_reply.started": "2024-08-29T16:50:37.606482Z"
        },
        "id": "H8vQPx1TfiJY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.rename(columns={'statement': 'original_statement'}, inplace=True)\n",
        "\n",
        "df['statement']=df['original_statement'].str.lower()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:37.732405Z",
          "iopub.status.busy": "2024-08-29T16:50:37.732075Z",
          "iopub.status.idle": "2024-08-29T16:50:39.362974Z",
          "shell.execute_reply": "2024-08-29T16:50:39.361832Z",
          "shell.execute_reply.started": "2024-08-29T16:50:37.732369Z"
        },
        "id": "gEG4jpzqfiJa",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def remove_patterns(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    # Remove markdown-style links\n",
        "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "    # Remove handles (that start with '@')\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove punctuation and other special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply the function to the 'statement' column\n",
        "df['statement'] = df['statement'].apply(remove_patterns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:50:39.364654Z",
          "iopub.status.busy": "2024-08-29T16:50:39.364224Z",
          "iopub.status.idle": "2024-08-29T16:51:37.338988Z",
          "shell.execute_reply": "2024-08-29T16:51:37.33786Z",
          "shell.execute_reply.started": "2024-08-29T16:50:39.364608Z"
        },
        "id": "ucf1JyrQfiJc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Apply word_tokenize to each element in the 'statement' column\n",
        "df['tokens'] = df['statement'].apply(word_tokenize)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:51:37.340399Z",
          "iopub.status.busy": "2024-08-29T16:51:37.340079Z",
          "iopub.status.idle": "2024-08-29T16:54:15.632627Z",
          "shell.execute_reply": "2024-08-29T16:54:15.631547Z",
          "shell.execute_reply.started": "2024-08-29T16:51:37.340364Z"
        },
        "id": "exZwtlCEfiJd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize the stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to stem tokens and convert them to strings\n",
        "def stem_tokens(tokens):\n",
        "    return ' '.join(stemmer.stem(str(token)) for token in tokens)\n",
        "\n",
        "# Apply the function to the 'tokens' column\n",
        "df['tokens_stemmed'] = df['tokens'].apply(stem_tokens)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:54:15.634207Z",
          "iopub.status.busy": "2024-08-29T16:54:15.633861Z",
          "iopub.status.idle": "2024-08-29T16:54:46.393144Z",
          "shell.execute_reply": "2024-08-29T16:54:46.392116Z",
          "shell.execute_reply.started": "2024-08-29T16:54:15.634172Z"
        },
        "id": "ugRaVrGBfiJz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get unique categories in 'status'\n",
        "statuses = df['status'].unique()\n",
        "\n",
        "# Define a color function\n",
        "def color_func(word, font_size, position, orientation, random_state=101, **kwargs):\n",
        "    return random.choice(colors)\n",
        "\n",
        "# Generate and plot the WordCloud for each category\n",
        "for status in statuses:\n",
        "    # Filter the tokens data for the current status\n",
        "    tokens_data = ' '.join(df[df['status'] == status]['tokens'].dropna().apply(lambda x: ' '.join(x)).tolist())\n",
        "\n",
        "    # Generate the WordCloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=color_func).generate(tokens_data)\n",
        "\n",
        "    # Plot the WordCloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')  # Turn off axis\n",
        "    plt.title(f'WordCloud for Status: {status}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXtPRL2wfiJ0"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:54:46.394857Z",
          "iopub.status.busy": "2024-08-29T16:54:46.394493Z",
          "iopub.status.idle": "2024-08-29T16:54:46.402891Z",
          "shell.execute_reply": "2024-08-29T16:54:46.401819Z",
          "shell.execute_reply.started": "2024-08-29T16:54:46.394819Z"
        },
        "id": "n_ZjENB3fiJ1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X = df[['tokens_stemmed', 'num_of_characters', 'num_of_sentences']]\n",
        "y = df['status']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:54:46.4045Z",
          "iopub.status.busy": "2024-08-29T16:54:46.404115Z",
          "iopub.status.idle": "2024-08-29T16:54:46.426488Z",
          "shell.execute_reply": "2024-08-29T16:54:46.425262Z",
          "shell.execute_reply.started": "2024-08-29T16:54:46.404461Z"
        },
        "id": "wj4zOCYLfiJ2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "lbl_enc = LabelEncoder()\n",
        "y = lbl_enc.fit_transform(y.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:54:46.42845Z",
          "iopub.status.busy": "2024-08-29T16:54:46.427924Z",
          "iopub.status.idle": "2024-08-29T16:54:46.443924Z",
          "shell.execute_reply": "2024-08-29T16:54:46.442932Z",
          "shell.execute_reply.started": "2024-08-29T16:54:46.428404Z"
        },
        "id": "eTSXqNr_fiJ3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:54:46.445534Z",
          "iopub.status.busy": "2024-08-29T16:54:46.445162Z",
          "iopub.status.idle": "2024-08-29T16:55:03.368491Z",
          "shell.execute_reply": "2024-08-29T16:55:03.367456Z",
          "shell.execute_reply.started": "2024-08-29T16:54:46.445493Z"
        },
        "id": "Ook-hfQ-fiJ4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 1. Initialize TF-IDF Vectorizer and fit/transform on the 'tokens' column\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=50000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train['tokens_stemmed'])\n",
        "X_test_tfidf = vectorizer.transform(X_test['tokens_stemmed'])\n",
        "\n",
        "# 2. Extract numerical features\n",
        "X_train_num = X_train[['num_of_characters', 'num_of_sentences']].values\n",
        "X_test_num = X_test[['num_of_characters', 'num_of_sentences']].values\n",
        "\n",
        "# 3. Combine TF-IDF features with numerical features\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_num])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_num])\n",
        "\n",
        "print('Number of feature words: ', len(vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:55:03.370541Z",
          "iopub.status.busy": "2024-08-29T16:55:03.370034Z",
          "iopub.status.idle": "2024-08-29T16:55:03.376867Z",
          "shell.execute_reply": "2024-08-29T16:55:03.375959Z",
          "shell.execute_reply.started": "2024-08-29T16:55:03.370489Z"
        },
        "id": "CK4e-We6fiJ5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train_combined.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:55:03.379271Z",
          "iopub.status.busy": "2024-08-29T16:55:03.378496Z",
          "iopub.status.idle": "2024-08-29T16:55:03.814968Z",
          "shell.execute_reply": "2024-08-29T16:55:03.813996Z",
          "shell.execute_reply.started": "2024-08-29T16:55:03.379235Z"
        },
        "id": "M3ybdaWofiJ6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Apply Random Over-Sampling on the vectorized data\n",
        "ros = RandomOverSampler(random_state=101)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_combined, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:55:03.816585Z",
          "iopub.status.busy": "2024-08-29T16:55:03.816229Z",
          "iopub.status.idle": "2024-08-29T16:55:03.823394Z",
          "shell.execute_reply": "2024-08-29T16:55:03.822219Z",
          "shell.execute_reply.started": "2024-08-29T16:55:03.816546Z"
        },
        "id": "phueZV1ifiJ6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "X_train_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjvQs0jqfiJ6"
      },
      "source": [
        "# Model Traning and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:55:03.825008Z",
          "iopub.status.busy": "2024-08-29T16:55:03.824654Z",
          "iopub.status.idle": "2024-08-29T16:55:03.833755Z",
          "shell.execute_reply": "2024-08-29T16:55:03.832672Z",
          "shell.execute_reply.started": "2024-08-29T16:55:03.824972Z"
        },
        "id": "WZyCYpUufiJ7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a dictionary of classifiers with their specific parameters.\n",
        "# Note: The hyperparameters for these classifiers were chosen after performing GridSearchCV to optimize performance.\n",
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "gpu_available = torch.cuda.is_available()\n",
        "\n",
        "classifiers = {\n",
        "    'Bernoulli Naive Bayes': BernoulliNB(alpha=0.1, binarize=0.0),\n",
        "    'XGB': XGBClassifier(\n",
        "        learning_rate=0.2,\n",
        "        max_depth=7,\n",
        "        n_estimators=500,\n",
        "        random_state=101,\n",
        "        tree_method='gpu_hist' if gpu_available else 'hist'  # Use GPU if available, else use CPU\n",
        "    )\n",
        "}\n",
        "\n",
        "# Print the classifiers to verify\n",
        "for name, classifier in classifiers.items():\n",
        "    print(f'{name}: {classifier}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T16:55:03.835835Z",
          "iopub.status.busy": "2024-08-29T16:55:03.835121Z",
          "iopub.status.idle": "2024-08-29T17:09:26.709385Z",
          "shell.execute_reply": "2024-08-29T17:09:26.708416Z",
          "shell.execute_reply.started": "2024-08-29T16:55:03.835787Z"
        },
        "id": "9TaGOoCLfiJ7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize a list to store accuracy scores for each classifier\n",
        "accuracy_scores = []\n",
        "\n",
        "# Iterate over each classifier and its name in the classifiers dictionary\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train_resampled, y_train_resampled)\n",
        "    y_pred = clf.predict(X_test_combined)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"For\", name)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Compute the confusion matrix for the predictions\n",
        "    # 'lbl_enc.classes_' provides the class labels for the confusion matrix and classification report\n",
        "    labels = lbl_enc.classes_\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    print(classification_report(y_test, y_pred, target_names=labels))\n",
        "\n",
        "    # Plot the confusion matrix using a heatmap\n",
        "    # Annotate each cell with the numeric value of the confusion matrix\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel('Predicted')  # Label for x-axis\n",
        "    plt.ylabel('Actual')     # Label for y-axis\n",
        "    plt.title(f'Confusion Matrix for {name}')  # Title for the heatmap\n",
        "    plt.show()  # Display the heatmap\n",
        "\n",
        "    # Append the accuracy score to the list\n",
        "    accuracy_scores.append(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "accuracies_df = pd.DataFrame({'Classifier': classifiers.keys(), 'Accuracy': accuracy_scores}).sort_values('Accuracy', ascending=False)\n",
        "best_classifier_name = accuracies_df.iloc[0]['Classifier']\n",
        "best_classifier = classifiers[best_classifier_name]\n",
        "\n",
        "# Simpan model\n",
        "dump(best_classifier, 'checkpoint/best_model.pkl')\n",
        "# Simpan TF-IDF vectorizer\n",
        "dump(vectorizer, 'checkpoint/vectorizer.pkl')\n",
        "# Simpan Label Encoder\n",
        "dump(lbl_enc, 'checkpoint/label_encoder.pkl')\n",
        "print(\"Model, TF-IDF Vectorizer, dan Label Encoder telah disimpan.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-29T17:09:26.711032Z",
          "iopub.status.busy": "2024-08-29T17:09:26.710721Z",
          "iopub.status.idle": "2024-08-29T17:09:27.078399Z",
          "shell.execute_reply": "2024-08-29T17:09:27.077349Z",
          "shell.execute_reply.started": "2024-08-29T17:09:26.710998Z"
        },
        "id": "3iPMx_r8fiJ8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to store classifier names and their corresponding accuracy scores\n",
        "accuracies_df = pd.DataFrame({'Classifier': classifiers.keys(), 'Accuracy': accuracy_scores}).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "palette = dict(zip(accuracies_df['Classifier'], colors[:4]))\n",
        "\n",
        "# Create a bar plot to visualize the accuracy of each classifier\n",
        "sns.barplot(x='Classifier', y='Accuracy', data=accuracies_df, palette=palette)\n",
        "\n",
        "plt.title(\"Classifier Accuracy Comparison\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Mental Health Sentiment Analysis | NLP | ML ðŸ§ ðŸŒŸ",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5338273,
          "sourceId": 8870083,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
